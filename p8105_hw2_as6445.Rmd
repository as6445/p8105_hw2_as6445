---
title: "p8105_hw2_as6445"
author: "Ayako Sekiya"
date: "2022-10-04"
output: github_document
---

```{r load_libraries, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
```

#Problem 1

This question is not graded.

I will first import the csv file and janior::clean names to clean the data. 

Then, I selected the variables that I wanted to include in my data set. 

I then changed the character variables for the entry variable into logical variables. 

```{r import_and_tidy}
transit_data = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
transit_data %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```


# Problem 2

I am importing the first sheet of the spreadsheet and tidy the data.

```{r tidy trashwheel data}
trashwheel_data = 
  readxl::read_excel("data/Trash Wheel Collection Data.xlsx", sheet=1, skip=1, range=cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(sports_balls=as.integer(round(sports_balls,0))) %>%
  add_column(name= "trash_wheel")

trashwheel_data
```

I will repeat similar steps for the professor wheel data to tidy the data. 

```{r tidy professor data}
professorwheel_data = 
  readxl::read_excel("data/Trash Wheel Collection Data.xlsx", sheet=2, skip= 1, range=cell_cols("A:M")) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>%
  mutate(dumpster = as.double(dumpster)) %>%
  mutate(year = as.character(year)) %>%
  add_column(name= "professor_wheel")

professorwheel_data
```

After the data is tidy, I will conduct a full merge of the two datasets I have cleaned. 

```{r fulljoin}
wheels_data = 
  full_join(trashwheel_data, professorwheel_data)

wheels_data
```
There are `r nrow(trashwheel_data)` observations and `r ncol(trashwheel_data)` columns in the Mr. Trashwheel data. There are `r nrow(professorwheel_data)` observations and `r ncol(professorwheel_data)` columns in the Professor Trashwheel data. There are `r nrow(wheels_data)` observations and `r ncol(wheels_data)`columns in the final combined dataset. The variables included are as following: `r colnames(wheels_data)`.  

The total weight of trash collected by Professor Trash Wheel is `r sum(professorwheel_data$weight_tons)`. 

The total number of sports balls collected by Mr. Trash Wheel in 2020 is `r trashwheel_data %>% filter(year == "2020") %>% pull(sports_balls) %>% sum()`. 

# Problem 3

I am importing three data files and tidied each file.

I first imported and tidied the `pols_month` dataset.
Note: Upon importing the dataset and viewing the dataset, there were values in prez_gop that were not included in the codebook. The codebook states that the values are 0 or 1, but the dataset includes 2 in 1974. This may be connected to the Watergate scandal, where there President Nixon was impeached. This should be further investigated. 

```{r pols}
pols= read_csv(file = "./Data/pols-month.csv") %>%
  janitor::clean_names() %>% 
  separate(mon, into=c("year", "month", "day"), sep= "-") %>%
  mutate(month=month.abb[as.numeric(month)]) %>%
  pivot_longer(
    cols= starts_with("prez_"),
    names_to = "president",
    names_prefix="prez_",
    values_to="number") %>%
  filter(!(number=="0")) %>%
  select(-day,-number) %>%
  mutate(year = as.double(year))
```

I then imported and tidied the `snp` dataset.

```{r snp}
snp = read_csv(file = "./Data/snp.csv")%>%
    janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = '/') %>% 
  mutate(year = as.numeric(year)) %>% 
  mutate(month = month.abb[as.numeric(month)]) %>% 
  select(-day) %>% 
  mutate(year=if_else(year<23, year+2000, year+1900))
```

I then imported and tidied the `unemployment` dataset.

```{r unemployment data}
unemployment = read_csv(file = "./Data/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemployment") %>%
    mutate(year = as.double(year))
```

I then created a final dataset called `merged_dataset` and did a left join to acheive this.

```{r merge}
snp_pols_data= left_join(pols, snp)
merged_data=left_join(snp_pols_data, unemployment)
```

There are `r nrow(pols)` observations and `r ncol(pols)` columns in the pols dataset. The variables included are as following: `r colnames(pols)`. This dataset includes the number of republican and democratic presidents, govenors, senators and house of representatives. The range of years is (`r range(pols$year)`).

There are `r nrow(snp)` observations and `r ncol(snp)` columns in the snp dataset. The variables included are as following: `r colnames(snp)`.  Close is the closing values of the S&P stock index for the corresponding month. The range of years is (`r range(snp$year)`).
 
There are `r nrow(unemployment)` observations and `r ncol(unemployment)` columns in the unemployment dataset.The variables included are as following: `r colnames(unemployment)`. Unemployment shows the percentage of unemployment for each month.The range of years is (`r range(unemployment$year)`).

There are `r nrow(merged_data)` observations and `r ncol(merged_data)` columns in the final combined dataset. The variables included are as following: `r colnames(merged_data)`.The variables included are as following: `r colnames(merged_data)`. The range of years is (`r range(merged_data$year)`).