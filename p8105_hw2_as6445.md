p8105_hw2_as6445
================
Ayako Sekiya
2022-10-04

\#Problem 1

This question is not graded. Solutions will be posted later. Make sure
to include the code here still.

I will first import the csv file and janior::clean names to clean the
data.

Then, I selected the variables that I wanted to include in my data set.

I then changed the character variables for the entry variable into
logical variables.

``` r
transit_data = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not “tidy”: route number should be a
variable, as should route. That is, to obtain a tidy dataset we would
need to convert `route` variables from wide to long format. This will be
useful when focusing on specific routes, but may not be necessary when
considering questions that focus on station-level variables.

The following code chunk selects station name and line, and then uses
`distinct()` to obtain all unique combinations. As a result, the number
of rows in this dataset is the number of unique stations.

``` r
transit_data %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

The next code chunk is similar, but filters according to ADA compliance
as an initial step. This produces a dataframe in which the number of
rows is the number of ADA compliant stations.

``` r
transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

To compute the proportion of station entrances / exits without vending
allow entrance, we first exclude station entrances that do not allow
vending. Then, we focus on the `entry` variable – this logical, so
taking the mean will produce the desired proportion (recall that R will
coerce logical to numeric in cases like this).

``` r
transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

Lastly, we write a code chunk to identify stations that serve the A
train, and to assess how many of these are ADA compliant. As a first
step, we tidy the data as alluded to previously; that is, we convert
`route` from wide to long format. After this step, we can use tools from
previous parts of the question (filtering to focus on the A train, and
on ADA compliance; selecting and using `distinct` to obtain dataframes
with the required stations in rows).

``` r
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

# Problem 2

I am importing the first sheet of the spreadsheet which includes
information from trashwheel using `sheet`. I then tidied the data with
the general steps listed. I restricted the columns that are imported
into the dataframe to exclude columns with notes. I used `drop_na()` to
remove the rows that have NA for the dumpster column. I rounded the
number of sports balls to the nearest integer as well.

``` r
trashwheel_data = 
  readxl::read_excel("data/Trash Wheel Collection Data.xlsx", sheet=1, skip=1, range=cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(sports_balls=as.integer(round(sports_balls,0))) %>%
  add_column(name= "trash_wheel")

trashwheel_data
```

    ## # A tibble: 547 × 15
    ##    dumpster month year  date                weight_tons volume…¹ plast…² polys…³
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>    <dbl>   <dbl>   <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31       18    1450    1820
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74       13    1120    1030
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45       15    2450    3100
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1        15    2380    2730
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06       18     980     870
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71       13    1430    2140
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91        8     910    1090
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7        16    3580    4310
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52       14    2400    2790
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76       18    1340    1730
    ## # … with 537 more rows, 7 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, name <chr>, and abbreviated
    ## #   variable names ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene

I will repeat similar steps for the professor wheel data to tidy the
data.

``` r
professorwheel_data = 
  readxl::read_excel("data/Trash Wheel Collection Data.xlsx", sheet=2, skip= 1, range=cell_cols("A:M")) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>%
  mutate(dumpster = as.double(dumpster)) %>%
  mutate(year = as.character(year)) %>%
  add_column(name= "professor_wheel")

professorwheel_data
```

    ## # A tibble: 94 × 14
    ##    dumpster month    year  date                weight_…¹ volum…² plast…³ polys…⁴
    ##       <dbl> <chr>    <chr> <dttm>                  <dbl>   <dbl>   <dbl>   <dbl>
    ##  1        1 January  2017  2017-01-02 00:00:00      1.79      15    1950    6080
    ##  2        2 January  2017  2017-01-30 00:00:00      1.58      15    9540   11230
    ##  3        3 February 2017  2017-02-26 00:00:00      2.32      18    8350    9210
    ##  4        4 February 2017  2017-02-26 00:00:00      3.72      15    8590    1030
    ##  5        5 February 2017  2017-02-28 00:00:00      1.45      15    7830    9950
    ##  6        6 March    2017  2017-03-30 00:00:00      1.71      15    8210   10340
    ##  7        7 April    2017  2017-04-01 00:00:00      1.82      15    9830   11020
    ##  8        8 April    2017  2017-04-20 00:00:00      2.37      15    9240    8760
    ##  9        9 May      2017  2017-05-10 00:00:00      2.64      15    9540    8810
    ## 10       10 May      2017  2017-05-26 00:00:00      2.78      15    8230    7800
    ## # … with 84 more rows, 6 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   homes_powered <dbl>, name <chr>, and abbreviated variable names
    ## #   ¹​weight_tons, ²​volume_cubic_yards, ³​plastic_bottles, ⁴​polystyrene

After the data is tidy, I will conduct a full merge of the two datasets
I have cleaned.

``` r
wheels_data = 
  full_join(trashwheel_data, professorwheel_data)
```

    ## Joining, by = c("dumpster", "month", "year", "date", "weight_tons",
    ## "volume_cubic_yards", "plastic_bottles", "polystyrene", "cigarette_butts",
    ## "glass_bottles", "grocery_bags", "chip_bags", "homes_powered", "name")

``` r
wheels_data
```

    ## # A tibble: 641 × 15
    ##    dumpster month year  date                weight_tons volume…¹ plast…² polys…³
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>    <dbl>   <dbl>   <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31       18    1450    1820
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74       13    1120    1030
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45       15    2450    3100
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1        15    2380    2730
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06       18     980     870
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71       13    1430    2140
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91        8     910    1090
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7        16    3580    4310
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52       14    2400    2790
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76       18    1340    1730
    ## # … with 631 more rows, 7 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, name <chr>, and abbreviated
    ## #   variable names ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene

There are 547 observations and 15 columns in the Mr. Trashwheel data.
There are 94 observations and 14 columns in the Professor Trashwheel
data. There are 641 observations and 15rows in the final combined
dataset. The variables included are as following: dumpster, month, year,
date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
cigarette_butts, glass_bottles, grocery_bags, chip_bags, sports_balls,
homes_powered, name.

The total weight of trash collected by Professor Trash Wheel is 190.12.

The total number of sports balls collected by Mr. Trash Wheel in 2020 is
856.

# Problem 3

I am importing three data files and tidied each file.

Note: Upon importing the dataset and viewing the dataset, there were
values in prez_gop that were not included in the codebook. The codebook
states that the values are 0 or 1, but the dataset includes 2 in 1974.
This may be connected to the Watergate scandal, where there President
Nixon was impeached. This should be further investigated.

``` r
pols= read_csv(file = "./Data/pols-month.csv") %>%
  janitor::clean_names() %>% 
  separate(mon, into=c("year", "month", "day"), sep= "-") %>%
  mutate(month=month.abb[as.numeric(month)]) %>%
  pivot_longer(
    cols= starts_with("prez_"),
    names_to = "president",
    names_prefix="prez_",
    values_to="number") %>%
  filter(!(number=="0")) %>%
  select(-day,-number) %>%
  mutate(year = as.double(year))
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp = read_csv(file = "./Data/snp.csv")%>%
    janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), sep = '/') %>% 
  mutate(year = as.numeric(year)) %>% 
  mutate(month = month.abb[as.numeric(month)]) %>% 
  select(-day) %>% 
  mutate(year=if_else(year<23, year+2000, year+1900))
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

I decided to create two spreadsheets before 2000 and after 2000 to
better convert the years. There are other ways to do this, but I thought
this method was the most intuitive to me. Rather than using the `recode`
function, I used `month.abb` to convert the month number into month
name.

``` r
unemployment = read_csv(file = "./Data/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemployment") %>%
    mutate(year = as.double(year))
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_pols_data= left_join(pols, snp)
```

    ## Joining, by = c("year", "month")

``` r
merged_data=left_join(snp_pols_data, unemployment)
```

    ## Joining, by = c("year", "month")

There are 822 observations and 9 columns in the pols dataset. The
variables included are as following: year, month, gov_gop, sen_gop,
rep_gop, gov_dem, sen_dem, rep_dem, president. This dataset includes the
number of republican and democratic presidents, govenors, senators and
house of representatives. The range of years is (1947, 2015).

There are 787 observations and 3 columns in the snp dataset. The
variables included are as following: month, year, close. Close is the
closing values of the S&P stock index for the corresponding month. The
range of years is (1950, 2015).

There are 816 observations and 3 columns in the unemployment dataset.The
variables included are as following: year, month, unemployment.
Unemployment shows the percentage of unemployment for each month.The
range of years is (1948, 2015).

There are 822 observations and 11 columns in the final combined dataset.
The variables included are as following: year, month, gov_gop, sen_gop,
rep_gop, gov_dem, sen_dem, rep_dem, president, close, unemployment.The
variables included are as following: year, month, gov_gop, sen_gop,
rep_gop, gov_dem, sen_dem, rep_dem, president, close, unemployment. The
range of years is (1947, 2015).
